#!/usr/bin/env python3\n\"\"\"\nData Validation Dashboard untuk User Testing Period\nMonitoring real-time data quality dan system performance\n\"\"\"\n\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport requests\nimport json\nfrom datetime import datetime, timedelta\nimport time\nfrom typing import Dict, List, Tuple\nimport sqlite3\nimport os\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Komoditas Watch - Data Validation Dashboard\",\n    page_icon=\"üìä\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\nclass DataValidationDashboard:\n    \"\"\"Dashboard untuk monitoring data quality selama user testing.\"\"\"\n    \n    def __init__(self):\n        self.api_base_url = os.getenv('API_BASE_URL', 'http://localhost:3000/api')\n        self.ml_api_url = os.getenv('ML_API_URL', 'http://localhost:8001/api/v1')\n        self.db_path = '/workspace/user-testing-materials/monitoring-dashboard/validation.db'\n        self.init_database()\n    \n    def init_database(self):\n        \"\"\"Initialize SQLite database untuk logging.\"\"\"\n        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # Table untuk data quality metrics\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS data_quality_log (\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                source TEXT,\n                metric_name TEXT,\n                value REAL,\n                status TEXT,\n                details TEXT\n            )\n        ''')\n        \n        # Table untuk system performance\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS performance_log (\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                endpoint TEXT,\n                response_time_ms INTEGER,\n                status_code INTEGER,\n                error_message TEXT\n            )\n        ''')\n        \n        # Table untuk user activity\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS user_activity_log (\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                session_id TEXT,\n                user_type TEXT,\n                action TEXT,\n                duration_seconds REAL,\n                success BOOLEAN\n            )\n        ''') \n        \n        conn.commit()\n        conn.close()\n    \n    def log_metric(self, source: str, metric_name: str, value: float, status: str, details: str = \"\"):\n        \"\"\"Log data quality metric.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO data_quality_log (source, metric_name, value, status, details)\n            VALUES (?, ?, ?, ?, ?)\n        ''', (source, metric_name, value, status, details))\n        \n        conn.commit()\n        conn.close()\n    \n    def log_performance(self, endpoint: str, response_time: int, status_code: int, error: str = \"\"):\n        \"\"\"Log system performance metric.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO performance_log (endpoint, response_time_ms, status_code, error_message)\n            VALUES (?, ?, ?, ?)\n        ''', (endpoint, response_time, status_code, error))\n        \n        conn.commit()\n        conn.close()\n    \n    def test_api_endpoints(self) -> Dict:\n        \"\"\"Test semua critical API endpoints.\"\"\"\n        endpoints = {\n            \"Backend Health\": f\"{self.api_base_url}/health\",\n            \"Commodities\": f\"{self.api_base_url}/commodities\",\n            \"Prices\": f\"{self.api_base_url}/prices?commodity=CABAI_MERAH&region=32&limit=10\",\n            \"Weather\": f\"{self.api_base_url}/weather?region=32&limit=5\",\n            \"ML Health\": f\"{self.ml_api_url}/health\",\n            \"ML Prediction\": f\"{self.ml_api_url}/predict/price/CABAI_MERAH\",\n            \"ML Stats\": f\"{self.ml_api_url}/stats\"\n        }\n        \n        results = {}\n        \n        for name, url in endpoints.items():\n            try:\n                start_time = time.time()\n                \n                if \"ML Prediction\" in name:\n                    # POST request untuk ML prediction\n                    payload = {\n                        \"region_code\": \"32\",\n                        \"horizon_days\": 7,\n                        \"model_type\": \"prophet\",\n                        \"include_uncertainty\": True\n                    }\n                    response = requests.post(url, json=payload, timeout=10)\n                else:\n                    response = requests.get(url, timeout=10)\n                \n                response_time = int((time.time() - start_time) * 1000)\n                \n                results[name] = {\n                    \"status_code\": response.status_code,\n                    \"response_time_ms\": response_time,\n                    \"status\": \"‚úÖ OK\" if response.status_code == 200 else \"‚ùå ERROR\",\n                    \"error\": \"\" if response.status_code == 200 else f\"HTTP {response.status_code}\"\n                }\n                \n                # Log performance\n                self.log_performance(name, response_time, response.status_code, results[name][\"error\"])\n                \n            except Exception as e:\n                results[name] = {\n                    \"status_code\": 0,\n                    \"response_time_ms\": 0,\n                    \"status\": \"‚ùå ERROR\",\n                    \"error\": str(e)\n                }\n                self.log_performance(name, 0, 0, str(e))\n        \n        return results\n    \n    def validate_data_quality(self) -> Dict:\n        \"\"\"Validate quality dari sample data.\"\"\"\n        metrics = {}\n        \n        try:\n            # Load sample data\n            price_data_path = '/workspace/user-testing-materials/sample-data/historical_prices_demo.csv'\n            weather_data_path = '/workspace/user-testing-materials/sample-data/weather_data_demo.csv'\n            \n            if os.path.exists(price_data_path):\n                price_df = pd.read_csv(price_data_path)\n                \n                # Completeness metrics\n                total_records = len(price_df)\n                missing_prices = price_df['price'].isna().sum()\n                completeness = (1 - missing_prices / total_records) * 100\n                \n                metrics['Price Data Completeness'] = {\n                    'value': completeness,\n                    'status': '‚úÖ GOOD' if completeness >= 95 else '‚ö†Ô∏è WARNING' if completeness >= 90 else '‚ùå POOR',\n                    'details': f'{total_records} records, {missing_prices} missing prices'\n                }\n                \n                # Consistency metrics\n                negative_prices = (price_df['price'] < 0).sum()\n                zero_prices = (price_df['price'] == 0).sum()\n                consistency = (1 - (negative_prices + zero_prices) / total_records) * 100\n                \n                metrics['Price Data Consistency'] = {\n                    'value': consistency,\n                    'status': '‚úÖ GOOD' if consistency >= 98 else '‚ö†Ô∏è WARNING' if consistency >= 95 else '‚ùå POOR',\n                    'details': f'{negative_prices} negative, {zero_prices} zero prices'\n                }\n                \n                # Timeliness metrics\n                price_df['date'] = pd.to_datetime(price_df['date'])\n                latest_date = price_df['date'].max()\n                days_old = (datetime.now() - latest_date).days\n                timeliness = max(0, 100 - days_old * 10)  # Penalize 10% per day\n                \n                metrics['Data Timeliness'] = {\n                    'value': timeliness,\n                    'status': '‚úÖ FRESH' if days_old <= 1 else '‚ö†Ô∏è STALE' if days_old <= 3 else '‚ùå OLD',\n                    'details': f'Latest data: {latest_date.strftime(\"%Y-%m-%d\")} ({days_old} days old)'\n                }\n                \n                # Log metrics\n                for metric_name, metric_data in metrics.items():\n                    self.log_metric('sample_data', metric_name, metric_data['value'], metric_data['status'], metric_data['details'])\n            \n            if os.path.exists(weather_data_path):\n                weather_df = pd.read_csv(weather_data_path)\n                \n                # Weather data coverage\n                weather_types = weather_df['weather_type'].unique()\n                expected_types = ['TEMPERATURE', 'RAINFALL', 'HUMIDITY']\n                coverage = len(set(weather_types) & set(expected_types)) / len(expected_types) * 100\n                \n                metrics['Weather Data Coverage'] = {\n                    'value': coverage,\n                    'status': '‚úÖ COMPLETE' if coverage == 100 else '‚ö†Ô∏è PARTIAL' if coverage >= 66 else '‚ùå INCOMPLETE',\n                    'details': f'Available: {\", \".join(weather_types)}'\n                }\n                \n                self.log_metric('sample_data', 'Weather Data Coverage', coverage, metrics['Weather Data Coverage']['status'], metrics['Weather Data Coverage']['details'])\n        \n        except Exception as e:\n            metrics['Data Validation Error'] = {\n                'value': 0,\n                'status': '‚ùå ERROR',\n                'details': str(e)\n            }\n            self.log_metric('sample_data', 'Validation Error', 0, '‚ùå ERROR', str(e))\n        \n        return metrics\n    \n    def get_historical_metrics(self, hours: int = 24) -> pd.DataFrame:\n        \"\"\"Get historical metrics dari database.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        \n        query = '''\n            SELECT timestamp, source, metric_name, value, status\n            FROM data_quality_log \n            WHERE timestamp >= datetime('now', '-{} hours')\n            ORDER BY timestamp DESC\n        '''.format(hours)\n        \n        df = pd.read_sql_query(query, conn)\n        conn.close()\n        \n        return df\n    \n    def get_performance_metrics(self, hours: int = 24) -> pd.DataFrame:\n        \"\"\"Get performance metrics dari database.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        \n        query = '''\n            SELECT timestamp, endpoint, response_time_ms, status_code\n            FROM performance_log \n            WHERE timestamp >= datetime('now', '-{} hours')\n            AND response_time_ms > 0\n            ORDER BY timestamp DESC\n        '''.format(hours)\n        \n        df = pd.read_sql_query(query, conn)\n        conn.close()\n        \n        return df\n    \n    def render_dashboard(self):\n        \"\"\"Render main dashboard.\"\"\"\n        st.title(\"üìä Data Validation Dashboard\")\n        st.markdown(\"**User Testing Period Monitoring** - Real-time data quality dan system performance\")\n        \n        # Sidebar controls\n        st.sidebar.header(\"‚öôÔ∏è Controls\")\n        auto_refresh = st.sidebar.checkbox(\"Auto Refresh (30s)\", value=True)\n        refresh_interval = st.sidebar.selectbox(\"Refresh Interval\", [10, 30, 60, 300], index=1)\n        \n        if auto_refresh:\n            time.sleep(refresh_interval)\n            st.rerun()\n        \n        # Manual refresh button\n        if st.sidebar.button(\"üîÑ Refresh Now\"):\n            st.rerun()\n        \n        # Main content\n        col1, col2 = st.columns([2, 1])\n        \n        with col1:\n            st.header(\"üéØ System Health Status\")\n            \n            # Test API endpoints\n            with st.spinner(\"Testing API endpoints...\"):\n                api_results = self.test_api_endpoints()\n            \n            # Display API status\n            status_cols = st.columns(3)\n            \n            for i, (endpoint, result) in enumerate(api_results.items()):\n                with status_cols[i % 3]:\n                    status_color = \"green\" if \"‚úÖ\" in result[\"status\"] else \"red\"\n                    st.metric(\n                        label=endpoint,\n                        value=f\"{result['response_time_ms']}ms\",\n                        delta=result[\"status\"]\n                    )\n                    if result[\"error\"]:\n                        st.error(f\"Error: {result['error']}\")\n        \n        with col2:\n            st.header(\"üìà Quick Stats\")\n            \n            # Current timestamp\n            st.info(f\"‚è∞ Last Update: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n            \n            # System uptime (simulated)\n            uptime_hours = 24  # Could be calculated from logs\n            st.success(f\"‚ö° Uptime: {uptime_hours}h\")\n            \n            # Active users (simulated)\n            active_users = np.random.randint(5, 25)\n            st.info(f\"üë• Active Sessions: {active_users}\")\n        \n        # Data Quality Section\n        st.header(\"üîç Data Quality Validation\")\n        \n        with st.spinner(\"Validating data quality...\"):\n            quality_metrics = self.validate_data_quality()\n        \n        if quality_metrics:\n            quality_cols = st.columns(len(quality_metrics))\n            \n            for i, (metric_name, metric_data) in enumerate(quality_metrics.items()):\n                with quality_cols[i % len(quality_cols)]:\n                    st.metric(\n                        label=metric_name,\n                        value=f\"{metric_data['value']:.1f}%\" if metric_data['value'] > 0 else \"N/A\",\n                        delta=metric_data['status']\n                    )\n                    st.caption(metric_data['details'])\n        \n        # Performance Charts\n        st.header(\"üìä Performance Monitoring\")\n        \n        perf_df = self.get_performance_metrics(24)\n        \n        if not perf_df.empty:\n            # Response time chart\n            fig_response = px.line(\n                perf_df, \n                x='timestamp', \n                y='response_time_ms', \n                color='endpoint',\n                title=\"API Response Times (24h)\",\n                labels={'response_time_ms': 'Response Time (ms)', 'timestamp': 'Time'}\n            )\n            fig_response.update_layout(height=400)\n            st.plotly_chart(fig_response, use_container_width=True)\n            \n            # Success rate chart\n            perf_df['success'] = perf_df['status_code'] == 200\n            success_rate = perf_df.groupby('endpoint')['success'].mean() * 100\n            \n            fig_success = px.bar(\n                x=success_rate.index,\n                y=success_rate.values,\n                title=\"API Success Rate by Endpoint\",\n                labels={'x': 'Endpoint', 'y': 'Success Rate (%)'}\n            )\n            fig_success.update_layout(height=300)\n            st.plotly_chart(fig_success, use_container_width=True)\n        else:\n            st.info(\"No performance data available yet. Run some API tests first.\")\n        \n        # Historical Trends\n        st.header(\"üìà Historical Trends\")\n        \n        hist_df = self.get_historical_metrics(24)\n        \n        if not hist_df.empty:\n            # Group by metric type\n            metric_types = hist_df['metric_name'].unique()\n            \n            if len(metric_types) > 0:\n                selected_metric = st.selectbox(\"Select Metric\", metric_types)\n                \n                metric_data = hist_df[hist_df['metric_name'] == selected_metric]\n                \n                fig_trend = px.line(\n                    metric_data,\n                    x='timestamp',\n                    y='value',\n                    title=f\"{selected_metric} - 24h Trend\",\n                    labels={'value': 'Value', 'timestamp': 'Time'}\n                )\n                fig_trend.update_layout(height=300)\n                st.plotly_chart(fig_trend, use_container_width=True)\n        else:\n            st.info(\"No historical data available yet.\")\n        \n        # Alerts & Issues\n        st.header(\"üö® Active Alerts\")\n        \n        # Check for issues\n        issues = []\n        \n        for endpoint, result in api_results.items():\n            if \"‚ùå\" in result[\"status\"]:\n                issues.append(f\"**{endpoint}**: {result['error']}\")\n            elif result[\"response_time_ms\"] > 5000:\n                issues.append(f\"**{endpoint}**: Slow response ({result['response_time_ms']}ms)\")\n        \n        for metric_name, metric_data in quality_metrics.items():\n            if \"‚ùå\" in metric_data[\"status\"] or \"‚ö†Ô∏è\" in metric_data[\"status\"]:\n                issues.append(f\"**{metric_name}**: {metric_data['details']}\")\n        \n        if issues:\n            for issue in issues:\n                st.warning(issue)\n        else:\n            st.success(\"‚úÖ No active alerts - System operating normally\")\n        \n        # Raw Data Tables (Expandable)\n        with st.expander(\"üìã Raw Data Logs\"):\n            tab1, tab2 = st.tabs([\"Performance Logs\", \"Quality Logs\"])\n            \n            with tab1:\n                if not perf_df.empty:\n                    st.dataframe(perf_df.head(50), use_container_width=True)\n                else:\n                    st.info(\"No performance logs available\")\n            \n            with tab2:\n                if not hist_df.empty:\n                    st.dataframe(hist_df.head(50), use_container_width=True)\n                else:\n                    st.info(\"No quality logs available\")\n        \n        # Footer\n        st.markdown(\"---\")\n        st.markdown(\n            \"**Komoditas Watch Data Validation Dashboard** | \"\n            \"User Testing Period | \"\n            f\"Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n        )\n\ndef main():\n    \"\"\"Main dashboard application.\"\"\"\n    dashboard = DataValidationDashboard()\n    dashboard.render_dashboard()\n\nif __name__ == \"__main__\":\n    main()\n"
