"""FastAPI application untuk ML service."""

import time
import asyncio
from datetime import datetime
from typing import Dict, List, Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
import uvicorn

from app.config.settings import settings
from app.config.logging import ml_logger, setup_logging
from app.config.database import db_manager
from app.config.redis import redis_manager
from app.models.schemas import (\n    PredictionRequest, BatchPredictionRequest, PredictionResponse, BatchPredictionResponse,\n    AnomalyDetectionRequest, AnomalyDetectionResponse, \n    ModelPerformanceRequest, ModelPerformanceResponse,\n    RetrainingRequest, RetrainingResponse,\n    CorrelationAnalysisRequest, CorrelationAnalysisResponse,\n    HealthCheckResponse, ErrorResponseModel\n)\nfrom app.inference.predictor import prediction_service\nfrom app.training.trainer import ModelTrainer\n\n# Initialize logging\nsetup_logging()\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan events.\"\"\"\n    # Startup\n    ml_logger.info(\"Starting ML service application\")\n    \n    try:\n        # Connect to Redis\n        await redis_manager.connect()\n        ml_logger.info(\"Redis connected successfully\")\n        \n        # Test database connection\n        db_healthy = await db_manager.health_check()\n        if db_healthy:\n            ml_logger.info(\"Database connection verified\")\n        else:\n            ml_logger.warning(\"Database connection failed\")\n        \n        ml_logger.info(\"ML service startup completed\")\n        \n    except Exception as e:\n        ml_logger.error(\"Failed to initialize ML service\", error=str(e))\n        raise e\n    \n    yield\n    \n    # Shutdown\n    ml_logger.info(\"Shutting down ML service\")\n    try:\n        await redis_manager.disconnect()\n        await db_manager.close()\n        ml_logger.info(\"ML service shutdown completed\")\n    except Exception as e:\n        ml_logger.error(\"Error during shutdown\", error=str(e))\n\n\n# Create FastAPI app\napp = FastAPI(\n    title=settings.app_name,\n    version=settings.app_version,\n    description=\"Machine Learning service untuk prediksi harga komoditas Indonesia\",\n    lifespan=lifespan,\n    docs_url=\"/docs\" if settings.debug else None,\n    redoc_url=\"/redoc\" if settings.debug else None\n)\n\n# Add middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=settings.cors_origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.add_middleware(\n    TrustedHostMiddleware,\n    allowed_hosts=[\"*\"] if settings.debug else [\"localhost\", \"127.0.0.1\"]\n)\n\n\n# Request/Response middleware\n@app.middleware(\"http\")\nasync def log_requests(request: Request, call_next):\n    \"\"\"Log all requests for monitoring.\"\"\"\n    start_time = time.time()\n    \n    # Process request\n    response = await call_next(request)\n    \n    # Calculate duration\n    duration_ms = (time.time() - start_time) * 1000\n    \n    # Log request\n    ml_logger.log_api_request(\n        endpoint=str(request.url.path),\n        method=request.method,\n        status_code=response.status_code,\n        duration_ms=duration_ms\n    )\n    \n    return response\n\n\n# Exception handlers\n@app.exception_handler(HTTPException)\nasync def http_exception_handler(request: Request, exc: HTTPException):\n    \"\"\"Handle HTTP exceptions.\"\"\"\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"success\": False,\n            \"message\": exc.detail,\n            \"error_code\": f\"HTTP_{exc.status_code}\",\n            \"timestamp\": datetime.now().isoformat()\n        }\n    )\n\n\n@app.exception_handler(Exception)\nasync def general_exception_handler(request: Request, exc: Exception):\n    \"\"\"Handle general exceptions.\"\"\"\n    ml_logger.error(\n        \"Unhandled exception\",\n        endpoint=str(request.url.path),\n        method=request.method,\n        error=str(exc)\n    )\n    \n    return JSONResponse(\n        status_code=500,\n        content={\n            \"success\": False,\n            \"message\": \"Internal server error\",\n            \"error_code\": \"INTERNAL_ERROR\",\n            \"timestamp\": datetime.now().isoformat()\n        }\n    )\n\n\n# Health check endpoint\n@app.get(\"/health\", response_model=HealthCheckResponse)\nasync def health_check():\n    \"\"\"Check service health.\"\"\"\n    try:\n        health_status = await prediction_service.health_check()\n        \n        status = \"healthy\" if health_status.get(\"status\") == \"healthy\" else \"unhealthy\"\n        \n        return HealthCheckResponse(\n            status=status,\n            services={\n                \"database\": health_status.get(\"database\", False),\n                \"redis\": health_status.get(\"redis\", False),\n                \"models\": health_status.get(\"models_available\", False)\n            },\n            version=settings.app_version,\n            uptime_seconds=0,  # TODO: Calculate actual uptime\n            models_loaded=health_status.get(\"prediction_stats\", {}).get(\"models_loaded\", 0),\n            cache_hit_rate=health_status.get(\"prediction_stats\", {}).get(\"cache_hit_rate\", 0),\n            average_prediction_latency_ms=health_status.get(\"prediction_stats\", {}).get(\"average_latency_ms\", 0)\n        )\n        \n    except Exception as e:\n        ml_logger.error(\"Health check failed\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Health check failed\")\n\n\n# Prediction endpoints\n@app.post(\"/api/v1/predict/price/{commodity_code}\", response_model=PredictionResponse)\nasync def predict_commodity_price(\n    commodity_code: str,\n    request: PredictionRequest\n):\n    \"\"\"Predict price for a single commodity.\"\"\"\n    try:\n        # Override commodity code from path\n        request.commodity_code = commodity_code.upper()\n        \n        # Make prediction\n        prediction_result = await prediction_service.predict_price(\n            commodity_code=request.commodity_code,\n            region_code=request.region_code,\n            horizon_days=request.horizon_days,\n            model_type=request.model_type,\n            include_uncertainty=request.include_uncertainty,\n            include_features=request.include_features\n        )\n        \n        return PredictionResponse(\n            success=True,\n            message=\"Prediction completed successfully\",\n            **prediction_result\n        )\n        \n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        ml_logger.error(\"Prediction failed\", commodity_code=commodity_code, error=str(e))\n        raise HTTPException(status_code=500, detail=\"Prediction failed\")\n\n\n@app.post(\"/api/v1/predict/batch\", response_model=BatchPredictionResponse)\nasync def batch_predict_prices(\n    request: BatchPredictionRequest\n):\n    \"\"\"Perform batch predictions for multiple commodities.\"\"\"\n    try:\n        # Convert requests to dict format\n        batch_requests = [req.dict() for req in request.requests]\n        \n        # Perform batch prediction\n        batch_result = await prediction_service.batch_predict(\n            requests=batch_requests,\n            max_workers=5\n        )\n        \n        return BatchPredictionResponse(\n            success=True,\n            message=\"Batch prediction completed\",\n            **batch_result\n        )\n        \n    except Exception as e:\n        ml_logger.error(\"Batch prediction failed\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Batch prediction failed\")\n\n\n# Anomaly detection endpoints\n@app.post(\"/api/v1/predict/anomaly\", response_model=AnomalyDetectionResponse)\nasync def detect_price_anomalies(\n    request: AnomalyDetectionRequest\n):\n    \"\"\"Detect price anomalies.\"\"\"\n    try:\n        anomaly_result = await prediction_service.detect_anomalies(\n            commodity_code=request.commodity_code,\n            region_code=request.region_code,\n            detection_type=request.detection_type,\n            sensitivity=request.sensitivity,\n            time_window_days=request.time_window_days\n        )\n        \n        return AnomalyDetectionResponse(\n            success=True,\n            message=\"Anomaly detection completed\",\n            **anomaly_result\n        )\n        \n    except Exception as e:\n        ml_logger.error(\"Anomaly detection failed\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Anomaly detection failed\")\n\n\n@app.get(\"/api/v1/predict/anomaly/{region_code}\", response_model=AnomalyDetectionResponse)\nasync def detect_regional_anomalies(\n    region_code: str,\n    commodity_code: Optional[str] = None,\n    detection_type: str = \"both\",\n    sensitivity: float = 0.1,\n    time_window_days: int = 30\n):\n    \"\"\"Detect anomalies for a specific region.\"\"\"\n    try:\n        anomaly_result = await prediction_service.detect_anomalies(\n            commodity_code=commodity_code,\n            region_code=region_code,\n            detection_type=detection_type,\n            sensitivity=sensitivity,\n            time_window_days=time_window_days\n        )\n        \n        return AnomalyDetectionResponse(\n            success=True,\n            message=f\"Regional anomaly detection completed for {region_code}\",\n            **anomaly_result\n        )\n        \n    except Exception as e:\n        ml_logger.error(\n            \"Regional anomaly detection failed\",\n            region_code=region_code,\n            error=str(e)\n        )\n        raise HTTPException(status_code=500, detail=\"Regional anomaly detection failed\")\n\n\n# Model management endpoints\n@app.get(\"/api/v1/models/accuracy\", response_model=ModelPerformanceResponse)\nasync def get_model_accuracy(\n    request: ModelPerformanceRequest = Depends()\n):\n    \"\"\"Get model performance metrics.\"\"\"\n    try:\n        # This is a placeholder - implement actual model performance tracking\n        performance_metrics = [\n            {\n                \"model_name\": \"prophet_beras_national\",\n                \"commodity_code\": \"BERAS\",\n                \"evaluation_period\": {\n                    \"start\": \"2024-01-01T00:00:00\",\n                    \"end\": \"2024-12-31T23:59:59\"\n                },\n                \"metrics\": {\n                    \"mae\": 1250.5,\n                    \"rmse\": 1875.3,\n                    \"mape\": 8.2,\n                    \"r2\": 0.85\n                },\n                \"predictions_count\": 365,\n                \"accuracy_trend\": []\n            }\n        ]\n        \n        return ModelPerformanceResponse(\n            success=True,\n            message=\"Model performance metrics retrieved\",\n            models_evaluated=len(performance_metrics),\n            performance_metrics=performance_metrics,\n            overall_statistics={\n                \"average_mape\": 8.2,\n                \"average_r2\": 0.85\n            }\n        )\n        \n    except Exception as e:\n        ml_logger.error(\"Failed to get model performance\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Failed to get model performance\")\n\n\n@app.post(\"/api/v1/models/retrain\", response_model=RetrainingResponse)\nasync def retrain_model(\n    request: RetrainingRequest,\n    background_tasks: BackgroundTasks\n):\n    \"\"\"Trigger model retraining.\"\"\"\n    try:\n        # Generate training ID\n        training_id = f\"train_{request.model_name}_{int(time.time())}\"\n        \n        # Start background training task\n        background_tasks.add_task(\n            _background_retrain,\n            training_id=training_id,\n            model_name=request.model_name,\n            commodity_codes=request.commodity_codes,\n            force_retrain=request.force_retrain,\n            hyperparameters=request.hyperparameters,\n            training_config=request.training_config\n        )\n        \n        return RetrainingResponse(\n            success=True,\n            message=\"Model retraining started\",\n            training_id=training_id,\n            model_name=request.model_name,\n            status=\"started\",\n            estimated_duration_minutes=30,\n            training_config=request.training_config or {}\n        )\n        \n    except Exception as e:\n        ml_logger.error(\"Failed to start model retraining\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Failed to start model retraining\")\n\n\nasync def _background_retrain(\n    training_id: str,\n    model_name: str,\n    commodity_codes: List[str] = None,\n    force_retrain: bool = False,\n    hyperparameters: Dict = None,\n    training_config: Dict = None\n):\n    \"\"\"Background task for model retraining.\"\"\"\n    try:\n        ml_logger.info(\"Starting background model retraining\", training_id=training_id)\n        \n        # Update training state\n        await redis_manager.set_training_state(\n            training_id,\n            {\n                \"status\": \"running\",\n                \"start_time\": datetime.now().isoformat(),\n                \"progress\": 0\n            }\n        )\n        \n        # Initialize trainer\n        trainer = ModelTrainer()\n        \n        # Train models for specified commodities\n        if commodity_codes:\n            for i, commodity_code in enumerate(commodity_codes):\n                try:\n                    training_results = trainer.train_commodity_models(\n                        commodity_code=commodity_code,\n                        model_types=[model_name] if model_name != \"all\" else [\"prophet\", \"lstm\"],\n                        retrain=force_retrain\n                    )\n                    \n                    # Update progress\n                    progress = int(((i + 1) / len(commodity_codes)) * 100)\n                    await redis_manager.set_training_state(\n                        training_id,\n                        {\n                            \"status\": \"running\",\n                            \"progress\": progress,\n                            \"current_commodity\": commodity_code,\n                            \"results\": training_results\n                        }\n                    )\n                    \n                except Exception as e:\n                    ml_logger.error(\n                        \"Failed to retrain commodity model\",\n                        training_id=training_id,\n                        commodity_code=commodity_code,\n                        error=str(e)\n                    )\n        \n        # Mark as completed\n        await redis_manager.set_training_state(\n            training_id,\n            {\n                \"status\": \"completed\",\n                \"progress\": 100,\n                \"end_time\": datetime.now().isoformat()\n            }\n        )\n        \n        ml_logger.info(\"Background model retraining completed\", training_id=training_id)\n        \n    except Exception as e:\n        ml_logger.error(\n            \"Background model retraining failed\",\n            training_id=training_id,\n            error=str(e)\n        )\n        \n        # Mark as failed\n        await redis_manager.set_training_state(\n            training_id,\n            {\n                \"status\": \"failed\",\n                \"error\": str(e),\n                \"end_time\": datetime.now().isoformat()\n            }\n        )\n\n\n# Analytics endpoints\n@app.post(\"/api/v1/analytics/correlation\", response_model=CorrelationAnalysisResponse)\nasync def analyze_weather_price_correlation(\n    request: CorrelationAnalysisRequest\n):\n    \"\"\"Analyze weather-price correlation.\"\"\"\n    try:\n        correlation_result = await prediction_service.analyze_price_correlation(\n            commodity_code=request.commodity_code,\n            region_codes=request.region_codes,\n            weather_types=request.weather_types,\n            time_window_days=request.time_window_days\n        )\n        \n        return CorrelationAnalysisResponse(\n            success=True,\n            message=\"Correlation analysis completed\",\n            **correlation_result\n        )\n        \n    except Exception as e:\n        ml_logger.error(\"Correlation analysis failed\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Correlation analysis failed\")\n\n\n# Utility endpoints\n@app.get(\"/api/v1/stats\")\nasync def get_service_stats():\n    \"\"\"Get service statistics.\"\"\"\n    try:\n        prediction_stats = prediction_service.get_prediction_stats()\n        cache_stats = await redis_manager.get_cache_stats()\n        \n        return {\n            \"success\": True,\n            \"message\": \"Service statistics retrieved\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"prediction_stats\": prediction_stats,\n            \"cache_stats\": cache_stats,\n            \"service_info\": {\n                \"name\": settings.app_name,\n                \"version\": settings.app_version,\n                \"environment\": settings.environment\n            }\n        }\n        \n    except Exception as e:\n        ml_logger.error(\"Failed to get service stats\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Failed to get service stats\")\n\n\n@app.get(\"/api/v1/supported\")\nasync def get_supported_data():\n    \"\"\"Get supported commodities and regions.\"\"\"\n    try:\n        return {\n            \"success\": True,\n            \"message\": \"Supported data retrieved\",\n            \"data\": {\n                \"commodities\": settings.supported_commodities,\n                \"regions\": settings.supported_regions,\n                \"model_types\": [\"prophet\", \"lstm\", \"ensemble\"],\n                \"detection_types\": [\"temporal\", \"geographic\", \"both\"],\n                \"weather_types\": [\"TEMPERATURE\", \"RAINFALL\", \"HUMIDITY\", \"WIND_SPEED\", \"PRESSURE\"]\n            }\n        }\n        \n    except Exception as e:\n        ml_logger.error(\"Failed to get supported data\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Failed to get supported data\")\n\n\n# Training status endpoint\n@app.get(\"/api/v1/training/{training_id}\")\nasync def get_training_status(training_id: str):\n    \"\"\"Get training status by ID.\"\"\"\n    try:\n        training_state = await redis_manager.get_training_state(training_id)\n        \n        if not training_state:\n            raise HTTPException(status_code=404, detail=\"Training ID not found\")\n        \n        return {\n            \"success\": True,\n            \"message\": \"Training status retrieved\",\n            \"training_id\": training_id,\n            \"status\": training_state\n        }\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        ml_logger.error(\"Failed to get training status\", training_id=training_id, error=str(e))\n        raise HTTPException(status_code=500, detail=\"Failed to get training status\")\n\n\nif __name__ == \"__main__\":\n    # Run server\n    uvicorn.run(\n        \"app.api.main:app\",\n        host=settings.api_host,\n        port=settings.api_port,\n        reload=settings.debug,\n        log_level=settings.log_level.lower()\n    )\n